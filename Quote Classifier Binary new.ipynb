{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas\n",
    "import random\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense , Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1='motivation - Sheet1.csv'\n",
    "filename3='happy - Sheet1.csv'\n",
    "#compiled is just happy and motivation quotes in one file\n",
    "filename='compiled.csv'\n",
    "#can add more classes here like calm by including csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_shuffle(filename):\n",
    "    dataframe = pandas.read_csv(filename, header=None)\n",
    "    ds = dataframe.sample(frac=1)\n",
    "    dataset = ds.values\n",
    "    X = dataset[:,0]\n",
    "    Y = dataset[:,1]\n",
    "    return X,Y\n",
    "X,Y=read_csv_shuffle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_y_labels(Y):\n",
    "    y_train=[]\n",
    "    for var in Y:\n",
    "        if(var==\"Happy\"):\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "    return y_train\n",
    "y_train=generate_y_labels(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_sentences(X):\n",
    "    sentences=[]\n",
    "    for row in X:\n",
    "        #print(row)\n",
    "        sentences.append(tf.compat.as_str(row).split())\n",
    "    return sentences\n",
    "sentences=generate_all_sentences(X)\n",
    "#print(sentences[6]) \n",
    "#print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list(sentences):\n",
    "    word_list=[]\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            word_list.append(word)\n",
    "    return word_list\n",
    "#split=sentence.split()\n",
    "#print(split)\n",
    "word_list=get_word_list(sentences)\n",
    "#print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "782\n"
     ]
    }
   ],
   "source": [
    "#I need to convert sentences to dictionary form\n",
    "#for that I need a dict\n",
    "def file_to_word_ids(word_list,sentences,word_to_id):\n",
    "    new_sentences=[]\n",
    "    for sentence in sentences:\n",
    "        new_sentences.append([word_to_id[word] for word in sentence if word in word_to_id])\n",
    "    #data = word_list\n",
    "    return new_sentences\n",
    "\n",
    "def get_dict(word_list,sentences):\n",
    "    counter = collections.Counter(word_list)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    vocabulary = len(word_to_id)\n",
    "    reverse_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "    train_data = file_to_word_ids(word_list,sentences, word_to_id)\n",
    "    return word_to_id,reverse_dictionary,vocabulary, train_data\n",
    "dictionary,reverse_dictionary,vocabulary, X_train=get_dict(word_list,sentences)\n",
    "print(len(X_train))\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 18\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_train[192:224]\n",
    "y_test=y_train[192:224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[:192]\n",
    "#Y_train=Y_train[:160]\n",
    "y_train=y_train[:192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='QuoteBinaryData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 18, 32)            25024     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 33,377\n",
      "Trainable params: 33,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "def build_model(hidden_size=32,use_dropout=True):\n",
    "    #embedding_vecor_length = 32\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary, hidden_size, input_length=max_review_length))\n",
    "    #model.add(LSTM(hidden_size,return_sequences=True))\n",
    "    model.add(LSTM(hidden_size))\n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "def train_model(model,reload_filename='NULL',save_best_only=True,batch_size=32,num_epochs=10):\n",
    "    if(save_best_only):\n",
    "        checkpointer = ModelCheckpoint(filepath=data_path + '/model-{epoch:02d}-{loss:.4f}.hdf5', verbose=1,monitor='val_acc', save_best_only=True, mode='auto')\n",
    "    else:\n",
    "        checkpointer = ModelCheckpoint(filepath=data_path + '/model-{epoch:02d}-{loss:.4f}.hdf5', verbose=1)\n",
    "    #period option in checkpointer -> after how many epochs to save the model\n",
    "    if(reload_filename!=\"NULL\"):\n",
    "            model = load_model(data_path + \"/\" + reload_filename)\n",
    "    model.fit(X_train, y_train, validation_split=0.3, epochs=num_epochs, batch_size=batch_size,callbacks=[checkpointer])\n",
    "    #model.save(data_path + \"final_model.hdf5\")\n",
    "    #if needed save final model\n",
    "hidden_size=32\n",
    "rnn_model=build_model()\n",
    "#add call back to save model after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 58 samples\n",
      "Epoch 1/50\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 0.0542 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.81034, saving model to QuoteBinaryData//model-01-0.0542.hdf5\n",
      "Epoch 2/50\n",
      "134/134 [==============================] - 0s 716us/step - loss: 0.0490 - acc: 1.0000 - val_loss: 0.7714 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.81034\n",
      "Epoch 3/50\n",
      "134/134 [==============================] - 0s 805us/step - loss: 0.0535 - acc: 0.9925 - val_loss: 0.6095 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81034 to 0.82759, saving model to QuoteBinaryData//model-03-0.0535.hdf5\n",
      "Epoch 4/50\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.6704 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.82759\n",
      "Epoch 5/50\n",
      "134/134 [==============================] - 0s 940us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.6526 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.82759\n",
      "Epoch 6/50\n",
      "134/134 [==============================] - 0s 747us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.7947 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.82759\n",
      "Epoch 7/50\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.0565 - acc: 0.9851 - val_loss: 0.6754 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.82759\n",
      "Epoch 8/50\n",
      "134/134 [==============================] - 0s 902us/step - loss: 0.0392 - acc: 0.9925 - val_loss: 0.7247 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.82759\n",
      "Epoch 9/50\n",
      "134/134 [==============================] - 0s 723us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.7108 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.82759\n",
      "Epoch 10/50\n",
      "134/134 [==============================] - 0s 917us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.5849 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.82759\n",
      "Epoch 11/50\n",
      "134/134 [==============================] - 0s 723us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.5773 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.82759\n",
      "Epoch 12/50\n",
      "134/134 [==============================] - 0s 753us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.6006 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.82759\n",
      "Epoch 13/50\n",
      "134/134 [==============================] - 0s 813us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82759\n",
      "Epoch 14/50\n",
      "134/134 [==============================] - 0s 761us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6831 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82759\n",
      "Epoch 15/50\n",
      "134/134 [==============================] - 0s 835us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6759 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.82759\n",
      "Epoch 16/50\n",
      "134/134 [==============================] - 0s 820us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.6942 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.82759\n",
      "Epoch 17/50\n",
      "134/134 [==============================] - 0s 716us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.82759\n",
      "Epoch 18/50\n",
      "134/134 [==============================] - 0s 709us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7564 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.82759\n",
      "Epoch 19/50\n",
      "134/134 [==============================] - 0s 798us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7570 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.82759\n",
      "Epoch 20/50\n",
      "134/134 [==============================] - 0s 716us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.8258 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.82759\n",
      "Epoch 21/50\n",
      "134/134 [==============================] - 0s 820us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7934 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.82759\n",
      "Epoch 22/50\n",
      "134/134 [==============================] - 0s 806us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.8025 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.82759 to 0.84483, saving model to QuoteBinaryData//model-22-0.0082.hdf5\n",
      "Epoch 23/50\n",
      "134/134 [==============================] - 0s 649us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8169 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.84483\n",
      "Epoch 24/50\n",
      "134/134 [==============================] - 0s 798us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.8482 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.84483\n",
      "Epoch 25/50\n",
      "134/134 [==============================] - 0s 686us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.9173 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.84483\n",
      "Epoch 26/50\n",
      "134/134 [==============================] - 0s 679us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.8751 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.84483\n",
      "Epoch 27/50\n",
      "134/134 [==============================] - 0s 765us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.8671 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.84483\n",
      "Epoch 28/50\n",
      "134/134 [==============================] - 0s 723us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.8761 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.84483\n",
      "Epoch 29/50\n",
      "134/134 [==============================] - 0s 716us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.9022 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.84483\n",
      "Epoch 30/50\n",
      "134/134 [==============================] - 0s 798us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.9524 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.84483\n",
      "Epoch 31/50\n",
      "134/134 [==============================] - 0s 701us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.84483\n",
      "Epoch 32/50\n",
      "134/134 [==============================] - 0s 709us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.9200 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.84483\n",
      "Epoch 33/50\n",
      "134/134 [==============================] - 0s 820us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.9293 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.84483\n",
      "Epoch 34/50\n",
      "134/134 [==============================] - 0s 709us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9347 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.84483\n",
      "Epoch 35/50\n",
      "134/134 [==============================] - 0s 679us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.9457 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.84483\n",
      "Epoch 36/50\n",
      "134/134 [==============================] - 0s 902us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.9528 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.84483\n",
      "Epoch 37/50\n",
      "134/134 [==============================] - 0s 828us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.9648 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.84483\n",
      "Epoch 38/50\n",
      "134/134 [==============================] - 0s 694us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.9779 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.84483\n",
      "Epoch 39/50\n",
      "134/134 [==============================] - 0s 791us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.9798 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.84483\n",
      "Epoch 40/50\n",
      "134/134 [==============================] - 0s 679us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.9916 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.84483\n",
      "Epoch 41/50\n",
      "134/134 [==============================] - 0s 664us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.84483\n",
      "Epoch 42/50\n",
      "134/134 [==============================] - 0s 813us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.9944 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.84483\n",
      "Epoch 43/50\n",
      "134/134 [==============================] - 0s 612us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.0033 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.84483\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 694us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.0185 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.84483\n",
      "Epoch 45/50\n",
      "134/134 [==============================] - 0s 731us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.0615 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.84483\n",
      "Epoch 46/50\n",
      "134/134 [==============================] - 0s 597us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.0536 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.84483\n",
      "Epoch 47/50\n",
      "134/134 [==============================] - 0s 649us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.0304 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.84483\n",
      "Epoch 48/50\n",
      "134/134 [==============================] - 0s 746us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.0342 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.84483\n",
      "Epoch 49/50\n",
      "134/134 [==============================] - 0s 679us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.0399 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.84483\n",
      "Epoch 50/50\n",
      "134/134 [==============================] - 0s 701us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.0475 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.84483\n"
     ]
    }
   ],
   "source": [
    "train_model(model=rnn_model,save_best_only=True,reload_filename=\"model-10-0.0704.hdf5\", num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 22ms/step\n",
      "Accuracy: 56.25%\n"
     ]
    }
   ],
   "source": [
    "def test_model_accuracy(filename):\n",
    "    model = load_model(data_path + \"/\" + filename)\n",
    "    scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "filename=\"model-10-0.0704.hdf5\"\n",
    "#change according to the file generated\n",
    "test_model_accuracy(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
