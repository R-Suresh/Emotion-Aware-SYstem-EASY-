{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas\n",
    "import random\n",
    "import cv2\n",
    "from pygame import mixer\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense , Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='C:/Users/RAHUL/projects/Many_to_one'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='C:/Users/RAHUL/Downloads/compiled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    dataframe = pandas.read_csv(filename, header=None)\n",
    "    #ds = dataframe.sample(frac=1)\n",
    "    dataset = dataframe.values\n",
    "    X = dataset[:,0]\n",
    "    #Y = dataset[:,1]\n",
    "    #ds.to_csv('compiled_predicted.csv')\n",
    "    return X\n",
    "X=read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_sentences(X):\n",
    "    sentences=[]\n",
    "    for row in X:\n",
    "        #print(row)\n",
    "        sentences.append(tf.compat.as_str(row).split())\n",
    "    return sentences\n",
    "sentences=generate_all_sentences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list(sentences):\n",
    "    word_list=[]\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            word_list.append(word)\n",
    "    return word_list\n",
    "word_list=get_word_list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "782\n"
     ]
    }
   ],
   "source": [
    "def file_to_word_ids(word_list,sentences,word_to_id):\n",
    "    new_sentences=[]\n",
    "    for sentence in sentences:\n",
    "        new_sentences.append([word_to_id[word] for word in sentence if word in word_to_id])\n",
    "    #data = word_list\n",
    "    return new_sentences\n",
    "\n",
    "def get_dict(word_list,sentences):\n",
    "    counter = collections.Counter(word_list)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    vocabulary = len(word_to_id)\n",
    "    reverse_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "    train_data = file_to_word_ids(word_list,sentences, word_to_id)\n",
    "    return word_to_id,reverse_dictionary,vocabulary, train_data\n",
    "dictionary,reverse_dictionary,vocabulary, X_train=get_dict(word_list,sentences)\n",
    "print(len(X_train))\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 18\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_quote_classes():\n",
    "    #should see how to test model in keras\n",
    "    #I can already train all 3 models and then load all 3 models\n",
    "    filename=\"binary_crossentropy/single 32 lstm/model-10-0.5622.hdf5\"\n",
    "    model = load_model(data_path + \"/\" + filename)\n",
    "    xnew=X_train\n",
    "    ynew = model.predict_classes(xnew)\n",
    "    #happy=list(range(1:117))\n",
    "    #motivation=list(range(117:231))\n",
    "    i=0\n",
    "    happy=[]\n",
    "    motivation=[]\n",
    "    #check whether index should start from 0 or 1\n",
    "    for clas in ynew:\n",
    "        if(clas==1):\n",
    "            #means the quote is happy\n",
    "            happy.append(i)\n",
    "        else:\n",
    "            motivation.append(i)\n",
    "        i=i+1\n",
    "    return happy,motivation\n",
    "\n",
    "def map_quote(happy,motivation,input_emotion):\n",
    "    if (input_emotion==\"happy\"):\n",
    "        #maps to happy quote\n",
    "        #print(\"Displaying happy quote\")\n",
    "        reply_quote=random.randint(0,len(happy))\n",
    "        #between 0 and len(happy) -1\n",
    "        #print (reply_quote+1)\n",
    "        reply_quote=happy[reply_quote]\n",
    "        #print(reply_quote)\n",
    "    elif (input_emotion==\"sad\"):\n",
    "        #maps to motivated quote\n",
    "        #print(\"Displaying motivated quote\")\n",
    "        reply_quote=random.randint(0,len(motivation))\n",
    "        #print (reply_quote+1)\n",
    "        reply_quote=motivation[reply_quote]\n",
    "        #print(reply_quote)\n",
    "    elif (input_emotion==\"disgust\"):\n",
    "        #maps to happy quote\n",
    "        #print(\"Displaying happy quote\")\n",
    "        reply_quote=random.randint(0,len(happy))\n",
    "        #print (reply_quote+1)\n",
    "        reply_quote=happy[reply_quote]\n",
    "        #print(reply_quote)\n",
    "    elif (input_emotion==\"fear\"):\n",
    "        #maps to motivated quote\n",
    "        #print(\"Displaying motivated quote\")\n",
    "        reply_quote=random.randint(0,len(motivation))\n",
    "        #print (reply_quote+1)\n",
    "        reply_quote=motivation[reply_quote]\n",
    "        #print(reply_quote)\n",
    "    elif (input_emotion==\"anger\"):\n",
    "        #maps to motivated quote\n",
    "        #print(\"Displaying motivated quote\")\n",
    "        reply_quote=random.randint(0,len(motivation))\n",
    "        #print (reply_quote+1)\n",
    "        reply_quote=motivation[reply_quote]\n",
    "        #print(reply_quote)\n",
    "    elif (input_emotion==\"surprise\"):\n",
    "        #maps to happy quote\n",
    "        #print(\"Displaying happy quote\")\n",
    "        reply_quote=random.randint(0,len(happy))\n",
    "        #print (reply_quote+1)\n",
    "        reply_quote=happy[reply_quote]\n",
    "        #print(reply_quote)\n",
    "    return reply_quote\n",
    "def display_quote(reply_quote_index):\n",
    "    #filename_pred='C:/Users/RAHUL/Downloads/compiled_predicted.csv'\n",
    "    filename='C:/Users/RAHUL/Downloads/compiled.csv'\n",
    "    dataframe = pandas.read_csv(filename, header=None)\n",
    "    dataset = dataframe.values\n",
    "    X = dataset[:,0]\n",
    "    return(X[reply_quote_index])\n",
    "def id2label(results):\n",
    "    if(results==0):\n",
    "        emotion='anger'\n",
    "    elif(results==1):\n",
    "        emotion='disgust'\n",
    "    elif(results==2):\n",
    "        emotion='fear'\n",
    "    elif(results==3):\n",
    "        emotion='happy'\n",
    "    elif(results==4):\n",
    "        emotion='sad'\n",
    "    elif(results==5):\n",
    "        emotion='surprise'\n",
    "    return emotion\n",
    "def predict_image_classes():\n",
    "    #load vgg model\n",
    "    \n",
    "    vgg_conv = VGG16(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(224, 224, 3))\n",
    "    #first load the keras image classification model\n",
    "    imagename = 'C:/Users/RAHUL/Desktop/capturing.jpg'\n",
    "    save_path='C:/Users/RAHUL/Downloads/images/'\n",
    "    # load an image in PIL format\n",
    "    original = load_img(imagename, target_size=(224, 224))\n",
    "    #print('PIL image size',original.size)\n",
    "    #plt.imshow(original)\n",
    "    #plt.show()\n",
    "\n",
    "    # convert the PIL image to a numpy array\n",
    "    # IN PIL - image is in (width, height, channel)\n",
    "    # In Numpy - image is in (height, width, channel)\n",
    "    numpy_image = img_to_array(original)\n",
    "    #plt.imshow(np.uint8(numpy_image))\n",
    "    #plt.show()\n",
    "    #print('numpy array size',numpy_image.shape)\n",
    "    # Convert the image / images into batch format\n",
    "    # expand_dims will add an extra dimension to the data at a particular axis\n",
    "    # We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
    "    # Thus we add the extra dimension to the axis 0.\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "    #print('image batch size', image_batch.shape)\n",
    "    #plt.imshow(np.uint8(image_batch[0]))\n",
    "    #now predict using the VGG model\n",
    "    #VGG predictions\n",
    "    # prepare the image for the VGG model\n",
    "    processed_image = vgg16.preprocess_input(image_batch)\n",
    "    #Idk why he had added .copy in the code\n",
    "    # get the predicted probabilities for each class\n",
    "    predictions = vgg_conv.predict(processed_image)\n",
    "    nVal=1\n",
    "    validation_features = np.zeros(shape=(nVal, 7, 7, 512))\n",
    "    validation_features=predictions\n",
    "    validation_features = np.reshape(validation_features, (nVal, 7 * 7 * 512))\n",
    "    model = load_model(save_path + 'final_emotion_model.hdf5')\n",
    "    results = model.predict_classes(validation_features)\n",
    "    \n",
    "    return id2label(results)\n",
    "def play_song(reply_music_index=0):\n",
    "    mixer.init()\n",
    "    mixer.music.load('C:/Users/RAHUL/Downloads/taki_taki.mp3')\n",
    "    mixer.music.play(start=15.0)\n",
    "def display_line(emotion):\n",
    "    if(emotion=='disgust'):\n",
    "        emotion='disgusted!'\n",
    "    elif(emotion=='anger'):\n",
    "        emotion='angry!'\n",
    "    elif(emotion=='surprise'):\n",
    "        emotion='surprised!'\n",
    "    elif(emotion=='fear'):\n",
    "        emotion='afraid'\n",
    "    elif(emotion=='happy'):\n",
    "        emotion='happy!'\n",
    "    print(\"Well, somebody seems to be \"+emotion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0 - \n",
    "#set up database lists\n",
    "#WARNING : RUN ONCE AT THE BEGGNING OF THE APP\n",
    "happy, motivation=predict_quote_classes()\n",
    "#happy_music, motivation_music=predict_music_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, somebody seems to be surprised!\n",
      "\n",
      "Here is some food for thought -\n",
      "\n",
      "the future belongs to those who believe in the beauty of their dreams\n"
     ]
    }
   ],
   "source": [
    "#while(1):\n",
    "\n",
    "#step 1-\n",
    "#getting the face classification model predictions -\n",
    "#live_feed()\n",
    "input_emotion=predict_image_classes()\n",
    "\n",
    "#step 2-\n",
    "#getting the reply quote index from the model\n",
    "display_line(input_emotion)\n",
    "print()\n",
    "print(\"Here is some food for thought -\")\n",
    "print()\n",
    "reply_quote_index=map_quote(happy,motivation,input_emotion)\n",
    "#reply_music_index=map_quote(happy_music,motivation_music,input_emotion)\n",
    "\n",
    "#step 3-\n",
    "#now display the quote from the CSV file\n",
    "#actually make it compiled_pred, else the model has to store the happy, motivated list in the memory \n",
    "print(display_quote(reply_quote_index))\n",
    "\n",
    "#step 4-\n",
    "#play_song(reply_music_index)\n",
    "play_song()\n",
    "#now repeat this after every song gets played and quit when the user types quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to make music classifier and then integrate images with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
